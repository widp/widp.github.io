<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Tejaswi&#39;s blog</title>
    <link>http://localhost:1313/blog/tags/statistics/</link>
    <description>Recent content in Statistics on Tejaswi&#39;s blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Jun 2023 00:00:00 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/blog/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sampling And Confidence Intervals</title>
      <link>http://localhost:1313/blog/posts/sampling_and_confidence_intervals/</link>
      <pubDate>Sun, 18 Jun 2023 00:00:00 +0530</pubDate>
      <guid>http://localhost:1313/blog/posts/sampling_and_confidence_intervals/</guid>
      <description>Beyond ratios : Sampling &amp;amp; confidence intervals Problem: Suppose we have 100 log lines, each line with a different severity level. INFO, WARN, SEVERE.&#xA;Since processing all of them might be expensive, How do we sample a proportion of these log lines? What can we say about the &amp;lsquo;population&amp;rsquo; of the log lines from this sample?&#xA;Confidence intervals It lets us make statements such as &amp;lsquo;with x% &amp;rsquo;level of confidence&amp;rsquo; the number of severe lines in the overall population will be between y and z.</description>
    </item>
  </channel>
</rss>
